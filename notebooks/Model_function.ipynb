{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Model_function.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "-pO5W6XvyO1u"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from sklearn.pipeline import Pipeline\n",
        "from tensorflow.keras import Sequential, regularizers\n",
        "\n",
        "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization, Flatten, ReLU\n",
        "from tensorflow.keras.activations import sigmoid, softmax, relu\n",
        "\n",
        "from spacy.tokenizer import Tokenizer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "from gensim.models import LdaMulticore\n",
        "from gensim.corpora import Dictionary\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.pipeline import Pipeline\n",
        "import joblib\n",
        "from keras.models import load_model\n",
        "import random"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Iz8u24sBbqr"
      },
      "source": [
        "# import the two encoders needed for data preprocessing"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MIF-yIp9Bh5-"
      },
      "source": [
        "# Tokenizer will be used to tokenize description text that is entered\n",
        "# into the function"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QyG7Bg6gydJd"
      },
      "source": [
        "tokenizer = joblib.load('tokenizer.joblib')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N0AlJrehBndF"
      },
      "source": [
        "# Encoder is used to LabelEncode the proerty types "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BIYD4tVq0Ru3"
      },
      "source": [
        "encoder = joblib.load('label_encoder.joblib')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DYtGrih4B2Tw"
      },
      "source": [
        "# Neural network model used for predictions"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c0hOdAieBVTy"
      },
      "source": [
        "combined = load_model('best_model.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kNwmDZsnB5Xq"
      },
      "source": [
        "# Creating two examples to input into the function to produce a prediction"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q8OC3hl0N6XC"
      },
      "source": [
        "test_text = \"\"\"\n",
        "Daniels House has 2 bedrooms and accepts pets\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2J8q4YUzB-b0"
      },
      "source": [
        "# List of all available labels that the neural network can calculate from\n",
        "# original Dataset. Because of label encoding, these have to be an exact \n",
        "# match in order for the function to run"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qM6HnFw02Yhz"
      },
      "source": [
        "test_list = ['Apartment', 'Condominium', 'Loft',                             \n",
        "             'House','Serviced apartment','Hostel',                \n",
        "             'Townhouse', 'Guest suite', 'Bed and breakfast',\n",
        "             'Guesthouse', 'Hotel', 'Other', 'Boutique hotel']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5JV7EFm6CJN_"
      },
      "source": [
        "# using python Random to create a random selection for the purpose of testing"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w0p3Ts-l3vu9"
      },
      "source": [
        "test = random.choice(test_list)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AgR777_QBhAW"
      },
      "source": [
        "def predict(property_type, description_text):\n",
        "\n",
        "  # For the model to predict, the labels must be in the format of a list\n",
        "  # These to lines take the property type input and append them into a list\n",
        "  # format\n",
        "\n",
        "    test_type = []\n",
        "    test_type.append(property_type)\n",
        "\n",
        "  # Once in list format, the property type has to be passed through the label\n",
        "  # encoder. In addition, once label encoded with then one-hot encode for the \n",
        "  # purpose of passing data through a wide format model\n",
        "    \n",
        "    building = encoder.transform(test_type)\n",
        "    building = keras.utils.to_categorical(building, 13)\n",
        "\n",
        "  # The next step embeds the description provided into tokens and bags of words\n",
        "  # padding is use to preserve the demensionality of the data \n",
        "\n",
        "    max_seq_length = 170\n",
        "    embed = tokenizer.texts_to_sequences(description_text)\n",
        "    embed = keras.preprocessing.sequence.pad_sequences(\n",
        "            embed, maxlen=max_seq_length, padding=\"post\")\n",
        "    \n",
        "  # Data then has to be transformed into a text matrix to be processed by the \n",
        "  # neural network. In order to function the label encoded list must match \n",
        "  # dimensions. For this we transform the list to match the size of the \n",
        "  # description text. The last step is to turn the list into a numpy array.\n",
        "\n",
        "    description_bow = tokenizer.texts_to_matrix(description_text)\n",
        "    building_transform =[list(building[0]) for n in range(\n",
        "                                                        description_bow.shape[0]\n",
        "                                                        )]\n",
        "    building = np.array(building_transform)\n",
        "\n",
        "  # We run a predict pipeline using the inputs of the description bow, label\n",
        "  # encoded building types, and the embedded works. This will return a numpy \n",
        "  # array of all possible predicitions. We use a f string to pull only the first\n",
        "  # prediction from the array.\n",
        "  \n",
        "    predictions = combined.predict([description_bow, building] + [embed])\n",
        "    val = predictions[0]\n",
        "\n",
        "    return f'The estimated rent is ${\"{:.2f}\".format(val[0])} per night.'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "bePBCuefF8dU",
        "outputId": "d13c0063-3344-41da-9e74-3ec0c9d21e96"
      },
      "source": [
        "predict(test, test_text)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'The estimated rent is $111.78 per night.'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KdE8tLO9BSmS"
      },
      "source": [
        "## Methodology\n",
        "\n",
        "Based on Britta Bettendorf's kaggle data \"Berlin Airbnb Data\", which contains information about Airbnb listings in Berlin, Germany in November 2018, we created a model that could predict the price of a hypothetical listing.\n",
        "We chose to base our predictions off of two elements of an Airbnb listing: type of property and listing description.\n",
        "\n",
        "\n",
        "In order to analyze and make predictions from the data, we first split the data into training (80 percent) and testing (20 percent) subdatasets. We fed the models the training data, and then tested the model's scores against the testing data.\n",
        "\n",
        "\n",
        "Our model is composed of two neural networks: a wide model and a deep model. The wide model provides the breadth needed to do a proper evaluation of the data. The deep model, with its embedding layers, does the deep text analysis of the listing descriptions.\n",
        "Insights:\n",
        "\n",
        "\n",
        "Model should have a margin of error of $15. However, it should be noted that the model is not 100 percent accurate, since it does not take into account any currency fluctuations, nor the coronavirus pandemic."
      ]
    }
  ]
}